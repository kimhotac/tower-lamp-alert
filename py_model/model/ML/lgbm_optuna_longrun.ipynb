{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0e8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM + Optuna 튜닝 (장기 실행, 중간 저장 포함)\n",
    "# 대상: 타워램프 상태 분류\n",
    "\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import joblib\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv('led_features_20250723_172434.csv')\n",
    "X = df.drop(columns=['label', 'image_name', 'label_name'])\n",
    "y = df['label']\n",
    "\n",
    "# 학습/검증 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# SQLite 기반 저장 가능한 Optuna Study 생성\n",
    "study = optuna.create_study(\n",
    "    study_name='lgbm_study',\n",
    "    direction='minimize',\n",
    "    storage='sqlite:///optuna_lgbm.db',\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "# Objective 함수 정의\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': 1000,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 16, 128),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 5.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 5.0),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': len(set(y)),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        callbacks=[early_stopping(50), log_evaluation(0)]\n",
    "    )\n",
    "    preds = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, preds)\n",
    "\n",
    "    # 중간 저장 (50 trial마다)\n",
    "    if trial.number % 50 == 0:\n",
    "        with open(\"optuna_best_params_temp.json\", \"w\") as f:\n",
    "            json.dump(study.best_params, f)\n",
    "        with open(\"optuna_best_score_temp.txt\", \"w\") as f:\n",
    "            f.write(f\"Best Accuracy: {1.0 - study.best_value:.5f}\")\n",
    "        joblib.dump(model, \"best_lgbm_model_temp.pkl\")\n",
    "\n",
    "    return 1.0 - acc\n",
    "\n",
    "# 튜닝 실행 (1000회, 이어서 가능)\n",
    "study.optimize(objective, n_trials=1000)\n",
    "\n",
    "# 최종 결과 저장\n",
    "with open(\"optuna_best_params.json\", \"w\") as f:\n",
    "    json.dump(study.best_params, f)\n",
    "\n",
    "with open(\"optuna_best_score.txt\", \"w\") as f:\n",
    "    f.write(f\"Best Accuracy: {1.0 - study.best_value:.5f}\")\n",
    "\n",
    "final_model = lgb.LGBMClassifier(**study.best_params)\n",
    "final_model.fit(X, y)\n",
    "joblib.dump(final_model, \"best_lgbm_model.pkl\")\n",
    "\n",
    "print(\"✅ 튜닝 완료. 최종 모델 및 파라미터 저장됨.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
