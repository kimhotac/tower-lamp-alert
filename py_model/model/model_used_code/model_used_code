import torch
import torch.nn as nn
from torchvision import transforms, models
from PIL import Image

# -------------------------
# [1] ì„¤ì •
# -------------------------
IMG_SIZE = 224
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model_path = r"C:\Users\Users\efficientnet_led_classifier.pth" # ëª¨ë¸ ê²½ë¡œ, ë³¸ì¸ì˜ ì»´í“¨í„°ì— ë§ê²Œ ìˆ˜ì •
class_names = ['off', 'green', 'yellow', 'red']  # 0,1,2,3

# -------------------------
# [2] ì „ì²˜ë¦¬ transform ì •ì˜
# -------------------------
transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

# -------------------------
# [3] ëª¨ë¸ ë¡œë”©
# -------------------------
model = models.efficientnet_b0(pretrained=False)
model.classifier[1] = nn.Linear(model.classifier[1].in_features, 4)
model.load_state_dict(torch.load(model_path, map_location=device))
model.to(device)
model.eval()

# -------------------------
# [4] ì˜ˆì¸¡ í•¨ìˆ˜ ì •ì˜
# -------------------------
def predict_led_image(image_path):
    try:
        image = Image.open(image_path).convert('RGB')
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return

    # ì „ì²˜ë¦¬
    input_tensor = transform(image).unsqueeze(0).to(device)

    # ëª¨ë¸ ì¶”ë¡ 
    with torch.no_grad():
        output = model(input_tensor)
        pred_class = torch.argmax(output, dim=1).item()

    print(f"ğŸ” ì˜ˆì¸¡ ê²°ê³¼: {class_names[pred_class]} ({pred_class})")

# -------------------------
# [5] ì‹¤í–‰ ì˜ˆì‹œ
# -------------------------
image_path = r"C:\Users\Users\crop_seperated\ecd1c91a-IMG_2674_2.jpg"  # í¬ë¡­ëœ LED ì´ë¯¸ì§€ ê²½ë¡œ
predict_led_image(image_path)
